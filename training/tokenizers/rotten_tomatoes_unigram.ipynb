{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import statements",
   "id": "7fac61a9935602e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T06:33:56.319509Z",
     "start_time": "2025-04-08T06:33:54.844036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast"
   ],
   "id": "b5acac93baacec66",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yegor/miniconda3/envs/ptorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data loading",
   "id": "264382bafc76e676"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-08T06:34:06.091854Z",
     "start_time": "2025-04-08T06:33:56.321804Z"
    }
   },
   "source": [
    "dataset = load_dataset(\"rotten_tomatoes\", split=\"train\")\n",
    "\n",
    "\n",
    "def get_training_corpus():\n",
    "    for i in range(0, len(dataset), 1000):\n",
    "        yield dataset[i: i + 1000][\"text\"]"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialization/training",
   "id": "5c68eb4070e02039"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T06:34:06.341569Z",
     "start_time": "2025-04-08T06:34:06.244913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = Tokenizer(models.Unigram())\n",
    "from tokenizers import Regex\n",
    "\n",
    "tokenizer.normalizer = normalizers.Sequence(\n",
    "    [\n",
    "        normalizers.Replace(\"``\", '\"'),\n",
    "        normalizers.Replace(\"''\", '\"'),\n",
    "        normalizers.NFKD(),\n",
    "        normalizers.StripAccents(),\n",
    "        normalizers.Replace(Regex(\" {2,}\"), \" \"),\n",
    "    ]\n",
    ")\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Metaspace()\n",
    "special_tokens = [\"<cls>\", \"<sep>\", \"<unk>\", \"<pad>\", \"<mask>\", \"<s>\", \"</s>\"]\n",
    "trainer = trainers.UnigramTrainer(\n",
    "    vocab_size=25000, special_tokens=special_tokens, unk_token=\"<unk>\"\n",
    ")\n",
    "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
   ],
   "id": "c6403cb857fa2909",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing",
   "id": "c15547d4842797f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T06:34:06.349389Z",
     "start_time": "2025-04-08T06:34:06.344982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoding = tokenizer.encode(\"Let's test this tokenizer.\")\n",
    "print(encoding.tokens)\n",
    "print(encoding.ids)\n",
    "print(tokenizer.decode(encoding.ids))\n",
    "print(len(tokenizer.get_vocab()))\n",
    "print(tokenizer.get_vocab_size())"
   ],
   "id": "a37327cf8395b8ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'L', 'e', \"t's\", '▁test', '▁this', '▁to', 'ke', 'niz', 'er', '.']\n",
      "[7, 2, 20, 2036, 1331, 35, 15, 3026, 10835, 99, 8]\n",
      "▁ e t's ▁test ▁this ▁to ke niz er .\n",
      "12344\n",
      "12344\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saving",
   "id": "fdc2d8d7e9e6bf6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T06:34:06.452779Z",
     "start_time": "2025-04-08T06:34:06.440400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=tokenizer,\n",
    "    bos_token=\"<s>\",\n",
    "    eos_token=\"</s>\",\n",
    "    unk_token=\"<unk>\",\n",
    "    pad_token=\"<pad>\",\n",
    "    cls_token=\"<cls>\",\n",
    "    sep_token=\"<sep>\",\n",
    "    mask_token=\"<mask>\",\n",
    "    padding_side=\"left\",\n",
    ")\n",
    "\n",
    "wrapped_tokenizer.save_pretrained(\"../../saved_models/tokenizers/rotten_tomatoes_unigram_style\")"
   ],
   "id": "1cf126076556d1f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../saved_models/tokenizers/rotten_tomatoes_unigram_style/tokenizer_config.json',\n",
       " '../../saved_models/tokenizers/rotten_tomatoes_unigram_style/special_tokens_map.json',\n",
       " '../../saved_models/tokenizers/rotten_tomatoes_unigram_style/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T06:34:06.502980Z",
     "start_time": "2025-04-08T06:34:06.492686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tok = AutoTokenizer.from_pretrained(\"../../saved_models/tokenizers/rotten_tomatoes_unigram_style\")\n",
    "\n",
    "tokens = tok.tokenize(\"Test number 2.!@#$%^&*()\")\n",
    "\n",
    "print(tokens)\n",
    "ids = tok.convert_tokens_to_ids(tokens)\n",
    "print(ids)\n",
    "decoded_string = tok.decode(ids)\n",
    "print(decoded_string)\n",
    "print(len(tok.get_vocab()))"
   ],
   "id": "c3bd6341db5e0347",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'T', 'est', '▁number', '▁2', '.', '!', '@', '#', '$', '%', '^', '&', '*', '(', ')']\n",
      "[7, 2, 536, 1684, 916, 8, 298, 2, 6832, 12339, 10445, 2, 1589, 1103, 153, 152]\n",
      "▁ <unk> est ▁number ▁2 . ! <unk> # $ % <unk> & * ( )\n",
      "12344\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
